{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Flatten, Activation, LSTM, Bidirectional, Add, SpatialDropout1D, GlobalAveragePooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Speech - Loaded 1440 samples\n",
      "✔️ Song - Loaded 1012 samples\n",
      "✅ Total samples (RAVDESS Speech + Song): 2452\n",
      "✅ X shape: (2452, 300, 17)\n",
      "✅ y shape: (2452,)\n",
      "\n",
      "Emotion label mapping:\n",
      "  0 → angry\n",
      "  1 → calm\n",
      "  2 → disgust\n",
      "  3 → fearful\n",
      "  4 → happy\n",
      "  5 → neutral\n",
      "  6 → sad\n",
      "  7 → surprised\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Paths\n",
    "ravdess_speech_path = '/Users/yathamlohithreddy/Desktop/vscodefloder /marsproject/Audio_Speech_Actors_01-24'\n",
    "ravdess_song_path   =  '/Users/yathamlohithreddy/Desktop/vscodefloder /marsproject/Audio_Song_Actors_01-24'\n",
    "\n",
    "# Settings\n",
    "max_len = 300\n",
    "SAMPLE_RATE = 16000\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "# Emotion map from RAVDESS (filename part 3: 03-01-XX-...)\n",
    "ravdess_emotion_map = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',\n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',\n",
    "    '08': 'surprised'\n",
    "}\n",
    "\n",
    "# === Load & Preprocess ===\n",
    "def load_and_preprocess(file_path, sr=SAMPLE_RATE):\n",
    "    y, _ = librosa.load(file_path, sr=sr)\n",
    "    y, _ = librosa.effects.trim(y, top_db=30)\n",
    "    y = y / np.max(np.abs(y)) if np.max(np.abs(y)) > 0 else y\n",
    "    return y\n",
    "\n",
    "# === Feature Extraction ===\n",
    "def extract_features(y, sr):\n",
    "    mfcc     = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    rolloff  = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    rms      = librosa.feature.rms(y=y)\n",
    "    zcr      = librosa.feature.zero_crossing_rate(y=y)\n",
    "\n",
    "    try:\n",
    "        f0 = librosa.yin(y, sr=sr, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
    "        f0 = f0.reshape(1, -1)\n",
    "    except:\n",
    "        f0 = np.zeros((1, mfcc.shape[1]))\n",
    "\n",
    "    T = mfcc.shape[1]\n",
    "    def resize(f): return f[:, :T] if f.shape[1] >= T else np.pad(f, ((0, 0), (0, T - f.shape[1])))\n",
    "    \n",
    "    all_features = np.vstack([\n",
    "        mfcc,\n",
    "        resize(rolloff),\n",
    "        resize(rms),\n",
    "        resize(zcr),\n",
    "        resize(f0)\n",
    "    ])\n",
    "    return all_features.T  # shape: (T, feature_dim)\n",
    "\n",
    "# === Process RAVDESS Dataset ===\n",
    "def process_ravdess(path, tag=\"\"):\n",
    "    count = 0\n",
    "    for actor_folder in os.listdir(path):\n",
    "        folder_path = os.path.join(path, actor_folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        for file in os.listdir(folder_path):\n",
    "            if not file.endswith(\".wav\"):\n",
    "                continue\n",
    "            parts = file.split(\"-\")\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            emotion_code = parts[2]\n",
    "            label = ravdess_emotion_map.get(emotion_code)\n",
    "            if not label:\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            y = load_and_preprocess(file_path)\n",
    "            features = extract_features(y, SAMPLE_RATE)\n",
    "\n",
    "            sequences.append(features)\n",
    "            labels.append(label)\n",
    "            count += 1\n",
    "    print(f\"✔️ {tag} - Loaded {count} samples\")\n",
    "\n",
    "# Process both datasets\n",
    "process_ravdess(ravdess_speech_path, tag=\"Speech\")\n",
    "process_ravdess(ravdess_song_path, tag=\"Song\")\n",
    "\n",
    "# === Finalize ===\n",
    "X = pad_sequences(sequences, maxlen=max_len, dtype='float32', padding='post', truncating='post')\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "\n",
    "# === Summary ===\n",
    "print(\"✅ Total samples (RAVDESS Speech + Song):\", len(labels))\n",
    "print(\"✅ X shape:\", X.shape)   # (samples, max_len, features)\n",
    "print(\"✅ y shape:\", y.shape)   # (samples,)\n",
    "\n",
    "print(\"\\nEmotion label mapping:\")\n",
    "for idx, emotion in enumerate(le.classes_):\n",
    "    print(f\"  {idx} → {emotion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled shapes: (2440, 300, 17) (2440,)\n"
     ]
    }
   ],
   "source": [
    "# suppose X.shape == (n_samples, timesteps, feat_dim)\n",
    "n_samples, timesteps, feat_dim = X_train.shape\n",
    "\n",
    "# 1) flatten\n",
    "X_flat = X_train.reshape(n_samples, timesteps * feat_dim)\n",
    "\n",
    "# 2) resample\n",
    "smote = SMOTE(random_state=42)\n",
    "X_flat_res, y_res = smote.fit_resample(X_flat, y_train)\n",
    "\n",
    "# 3) reshape back to sequences\n",
    "n_resampled = X_flat_res.shape[0]\n",
    "X_res = X_flat_res.reshape(n_resampled, timesteps, feat_dim)\n",
    "\n",
    "print(\"Resampled shapes:\", X_res.shape, y_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If y and y_resampled are Series, convert to arrays:\n",
    "# y_orig = y.values\n",
    "# y_res = y_resampled.values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "y_orig = np.array(y_train)\n",
    "y_resampled  = np.array(y_res)\n",
    "\n",
    "# Get sorted list of classes\n",
    "classes = np.unique(y_orig)\n",
    "\n",
    "# Count occurrences\n",
    "counts_before = [(y_orig == cls).sum() for cls in classes]\n",
    "counts_after  = [(y_resampled  == cls).sum() for cls in classes]\n",
    "\n",
    "# Plot side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axes[0].bar(classes, counts_before)\n",
    "axes[0].set_title('Class Distribution Before SMOTE')\n",
    "axes[0].set_xlabel('Class Label')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "axes[1].bar(classes, counts_after)\n",
    "axes[1].set_title('Class Distribution After SMOTE')\n",
    "axes[1].set_xlabel('Class Label')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented shape: (9760, 300, 17) (9760,)\n"
     ]
    }
   ],
   "source": [
    "def add_noise(X, noise_level=0.01):\n",
    "    noise = np.random.normal(0, noise_level, X.shape)\n",
    "    return X + noise\n",
    "\n",
    "def random_time_scaling(X, scale_range=(0.9, 1.1)):\n",
    "    scaled = []\n",
    "    for seq in X:\n",
    "        factor = np.random.uniform(*scale_range)\n",
    "        scaled.append(seq * factor)\n",
    "    return np.array(scaled)\n",
    "\n",
    "def time_mask(X, max_mask_size=5):\n",
    "    X_masked = X.copy()\n",
    "    for i in range(X.shape[0]):\n",
    "        t = np.random.randint(0, X.shape[1] - max_mask_size)\n",
    "        X_masked[i, t:t+max_mask_size, :] = 0\n",
    "    return X_masked\n",
    "\n",
    "X_augmented_noise = add_noise(X_res)\n",
    "X_augmented_scaled = random_time_scaling(X_res)\n",
    "X_augmented_masked = time_mask(X_res)\n",
    "\n",
    "X_aug = np.concatenate([X_res, X_augmented_noise, X_augmented_scaled, X_augmented_masked], axis=0)\n",
    "y_aug = np.concatenate([y_res] * 4, axis=0)\n",
    "\n",
    "print(\"Augmented shape:\", X_aug.shape, y_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">114,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m19,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m114,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m82,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m49,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m520\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">276,936</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m276,936\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">275,784</span> (1.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m275,784\u001b[0m (1.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, BatchNormalization, SpatialDropout1D,\n",
    "    GlobalAveragePooling1D, Dense\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Define shape variables\n",
    "num_emotions = len(np.unique(y_res))  # y_res: class labels\n",
    "timesteps, feat_dim = X_aug.shape[1], X_aug.shape[2]  # X_aug: audio features\n",
    "\n",
    "# Learning rate schedule\n",
    "initial_learning_rate = 1e-4\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=False\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Input(shape=(timesteps, feat_dim)),\n",
    "\n",
    "    Conv1D(128, kernel_size=9, activation='relu', padding='same',\n",
    "           kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    SpatialDropout1D(0.3),\n",
    "\n",
    "    Conv1D(128, kernel_size=7, activation='relu', padding='same',\n",
    "           kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    SpatialDropout1D(0.3),\n",
    "\n",
    "    Conv1D(128, kernel_size=5, activation='relu', padding='same',\n",
    "           kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    SpatialDropout1D(0.3),\n",
    "\n",
    "    Conv1D(128, kernel_size=3, activation='relu', padding='same',\n",
    "           kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    SpatialDropout1D(0.3),\n",
    "\n",
    "    Conv1D(64, kernel_size=1, activation='relu', padding='same',\n",
    "           kernel_regularizer=regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    SpatialDropout1D(0.3),\n",
    "\n",
    "    GlobalAveragePooling1D(),\n",
    "\n",
    "    Dense(num_emotions, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 3 ... 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "print(y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.1301 - loss: 2.2243"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 86ms/step - accuracy: 0.1301 - loss: 2.2242 - val_accuracy: 0.1670 - val_loss: 2.0926\n",
      "Epoch 2/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1634 - loss: 2.1199"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 96ms/step - accuracy: 0.1635 - loss: 2.1199 - val_accuracy: 0.1670 - val_loss: 2.0545\n",
      "Epoch 3/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 94ms/step - accuracy: 0.2080 - loss: 2.0541 - val_accuracy: 0.1405 - val_loss: 2.0615\n",
      "Epoch 4/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.2522 - loss: 1.9910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 95ms/step - accuracy: 0.2523 - loss: 1.9909 - val_accuracy: 0.2525 - val_loss: 1.9137\n",
      "Epoch 5/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.2924 - loss: 1.9197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 110ms/step - accuracy: 0.2925 - loss: 1.9196 - val_accuracy: 0.2485 - val_loss: 1.8752\n",
      "Epoch 6/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.3533 - loss: 1.8359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - accuracy: 0.3532 - loss: 1.8359 - val_accuracy: 0.3136 - val_loss: 1.7982\n",
      "Epoch 7/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.3787 - loss: 1.7687 - val_accuracy: 0.2811 - val_loss: 1.8111\n",
      "Epoch 8/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.3929 - loss: 1.7176 - val_accuracy: 0.3279 - val_loss: 1.8743\n",
      "Epoch 9/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.4196 - loss: 1.6713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 105ms/step - accuracy: 0.4196 - loss: 1.6712 - val_accuracy: 0.3625 - val_loss: 1.6447\n",
      "Epoch 10/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.4294 - loss: 1.6205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.4295 - loss: 1.6204 - val_accuracy: 0.3605 - val_loss: 1.6309\n",
      "Epoch 11/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 106ms/step - accuracy: 0.4551 - loss: 1.5740 - val_accuracy: 0.3523 - val_loss: 1.6476\n",
      "Epoch 12/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.4747 - loss: 1.5257 - val_accuracy: 0.3747 - val_loss: 1.6398\n",
      "Epoch 13/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.4856 - loss: 1.4860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 90ms/step - accuracy: 0.4856 - loss: 1.4860 - val_accuracy: 0.3931 - val_loss: 1.5656\n",
      "Epoch 14/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.4897 - loss: 1.4651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 92ms/step - accuracy: 0.4897 - loss: 1.4650 - val_accuracy: 0.4012 - val_loss: 1.5567\n",
      "Epoch 15/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5077 - loss: 1.4163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 91ms/step - accuracy: 0.5077 - loss: 1.4163 - val_accuracy: 0.4175 - val_loss: 1.4828\n",
      "Epoch 16/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5149 - loss: 1.4019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 94ms/step - accuracy: 0.5149 - loss: 1.4018 - val_accuracy: 0.4114 - val_loss: 1.4771\n",
      "Epoch 17/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 90ms/step - accuracy: 0.5272 - loss: 1.3648 - val_accuracy: 0.3971 - val_loss: 1.5417\n",
      "Epoch 18/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 88ms/step - accuracy: 0.5256 - loss: 1.3583 - val_accuracy: 0.4094 - val_loss: 1.4955\n",
      "Epoch 19/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 93ms/step - accuracy: 0.5351 - loss: 1.3215 - val_accuracy: 0.4114 - val_loss: 1.4793\n",
      "Epoch 20/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5493 - loss: 1.3034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 90ms/step - accuracy: 0.5493 - loss: 1.3034 - val_accuracy: 0.4277 - val_loss: 1.4362\n",
      "Epoch 21/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 93ms/step - accuracy: 0.5470 - loss: 1.2914 - val_accuracy: 0.4073 - val_loss: 1.5043\n",
      "Epoch 22/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.5630 - loss: 1.2588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 92ms/step - accuracy: 0.5630 - loss: 1.2588 - val_accuracy: 0.4318 - val_loss: 1.4344\n",
      "Epoch 23/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 93ms/step - accuracy: 0.5711 - loss: 1.2537 - val_accuracy: 0.4216 - val_loss: 1.4687\n",
      "Epoch 24/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 95ms/step - accuracy: 0.5691 - loss: 1.2280 - val_accuracy: 0.4175 - val_loss: 1.4822\n",
      "Epoch 25/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 93ms/step - accuracy: 0.5787 - loss: 1.2140 - val_accuracy: 0.4460 - val_loss: 1.4456\n",
      "Epoch 26/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5910 - loss: 1.1818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 95ms/step - accuracy: 0.5909 - loss: 1.1818 - val_accuracy: 0.4338 - val_loss: 1.4238\n",
      "Epoch 27/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.5800 - loss: 1.1964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.5800 - loss: 1.1964 - val_accuracy: 0.4216 - val_loss: 1.4110\n",
      "Epoch 28/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5941 - loss: 1.1625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - accuracy: 0.5941 - loss: 1.1626 - val_accuracy: 0.4745 - val_loss: 1.3410\n",
      "Epoch 29/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.5921 - loss: 1.1633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.5921 - loss: 1.1633 - val_accuracy: 0.4786 - val_loss: 1.3336\n",
      "Epoch 30/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.6052 - loss: 1.1476 - val_accuracy: 0.4562 - val_loss: 1.3741\n",
      "Epoch 31/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - accuracy: 0.6016 - loss: 1.1517 - val_accuracy: 0.4582 - val_loss: 1.3611\n",
      "Epoch 32/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - accuracy: 0.6100 - loss: 1.1208 - val_accuracy: 0.4542 - val_loss: 1.3876\n",
      "Epoch 33/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 97ms/step - accuracy: 0.6259 - loss: 1.0932 - val_accuracy: 0.4420 - val_loss: 1.3884\n",
      "Epoch 34/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - accuracy: 0.6115 - loss: 1.1078 - val_accuracy: 0.4481 - val_loss: 1.3878\n",
      "Epoch 35/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.6187 - loss: 1.1053 - val_accuracy: 0.4582 - val_loss: 1.3490\n",
      "Epoch 36/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - accuracy: 0.6232 - loss: 1.0810 - val_accuracy: 0.4277 - val_loss: 1.4023\n",
      "Epoch 37/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 476ms/step - accuracy: 0.6336 - loss: 1.0674 - val_accuracy: 0.4603 - val_loss: 1.3573\n",
      "Epoch 38/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 72ms/step - accuracy: 0.6415 - loss: 1.0541 - val_accuracy: 0.4705 - val_loss: 1.3443\n",
      "Epoch 39/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 76ms/step - accuracy: 0.6305 - loss: 1.0591 - val_accuracy: 0.4440 - val_loss: 1.3879\n",
      "Epoch 40/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6410 - loss: 1.0429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 83ms/step - accuracy: 0.6410 - loss: 1.0429 - val_accuracy: 0.4725 - val_loss: 1.3092\n",
      "Epoch 41/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 84ms/step - accuracy: 0.6324 - loss: 1.0479 - val_accuracy: 0.4847 - val_loss: 1.3246\n",
      "Epoch 42/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 89ms/step - accuracy: 0.6345 - loss: 1.0388 - val_accuracy: 0.4542 - val_loss: 1.3828\n",
      "Epoch 43/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 109ms/step - accuracy: 0.6496 - loss: 1.0281 - val_accuracy: 0.4684 - val_loss: 1.3252\n",
      "Epoch 44/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 111ms/step - accuracy: 0.6389 - loss: 1.0405 - val_accuracy: 0.4644 - val_loss: 1.3556\n",
      "Epoch 45/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6456 - loss: 1.0133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 104ms/step - accuracy: 0.6456 - loss: 1.0134 - val_accuracy: 0.4807 - val_loss: 1.2958\n",
      "Epoch 46/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.6549 - loss: 1.0083 - val_accuracy: 0.4582 - val_loss: 1.3559\n",
      "Epoch 47/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.6689 - loss: 0.9875 - val_accuracy: 0.4277 - val_loss: 1.4151\n",
      "Epoch 48/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 97ms/step - accuracy: 0.6615 - loss: 0.9825 - val_accuracy: 0.4684 - val_loss: 1.3105\n",
      "Epoch 49/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6566 - loss: 1.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.6567 - loss: 1.0043 - val_accuracy: 0.4990 - val_loss: 1.2538\n",
      "Epoch 50/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.6640 - loss: 0.9860 - val_accuracy: 0.4521 - val_loss: 1.3626\n",
      "Epoch 51/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - accuracy: 0.6750 - loss: 0.9741 - val_accuracy: 0.4888 - val_loss: 1.3263\n",
      "Epoch 52/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - accuracy: 0.6669 - loss: 0.9708 - val_accuracy: 0.4562 - val_loss: 1.3572\n",
      "Epoch 53/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 103ms/step - accuracy: 0.6671 - loss: 0.9641 - val_accuracy: 0.4664 - val_loss: 1.3368\n",
      "Epoch 54/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.6687 - loss: 0.9609 - val_accuracy: 0.4684 - val_loss: 1.3476\n",
      "Epoch 55/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.6727 - loss: 0.9576 - val_accuracy: 0.4745 - val_loss: 1.3102\n",
      "Epoch 56/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.6711 - loss: 0.9626 - val_accuracy: 0.4623 - val_loss: 1.3296\n",
      "Epoch 57/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 99ms/step - accuracy: 0.6716 - loss: 0.9689 - val_accuracy: 0.4644 - val_loss: 1.3441\n",
      "Epoch 58/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.6780 - loss: 0.9438 - val_accuracy: 0.4745 - val_loss: 1.3274\n",
      "Epoch 59/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 104ms/step - accuracy: 0.6813 - loss: 0.9349 - val_accuracy: 0.4684 - val_loss: 1.3012\n",
      "Epoch 60/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 110ms/step - accuracy: 0.6818 - loss: 0.9295 - val_accuracy: 0.4644 - val_loss: 1.3574\n",
      "Epoch 61/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 107ms/step - accuracy: 0.6802 - loss: 0.9395 - val_accuracy: 0.4664 - val_loss: 1.3426\n",
      "Epoch 62/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 92ms/step - accuracy: 0.6891 - loss: 0.9238 - val_accuracy: 0.4766 - val_loss: 1.3050\n",
      "Epoch 63/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.6824 - loss: 0.9264 - val_accuracy: 0.4847 - val_loss: 1.3031\n",
      "Epoch 64/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 96ms/step - accuracy: 0.6874 - loss: 0.9200 - val_accuracy: 0.4725 - val_loss: 1.3300\n",
      "Epoch 65/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 94ms/step - accuracy: 0.6892 - loss: 0.9221 - val_accuracy: 0.4766 - val_loss: 1.3192\n",
      "Epoch 66/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.6731 - loss: 0.9361 - val_accuracy: 0.4949 - val_loss: 1.2949\n",
      "Epoch 67/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 105ms/step - accuracy: 0.6917 - loss: 0.9149 - val_accuracy: 0.4827 - val_loss: 1.2946\n",
      "Epoch 68/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 104ms/step - accuracy: 0.6918 - loss: 0.9100 - val_accuracy: 0.4664 - val_loss: 1.3538\n",
      "Epoch 69/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.6843 - loss: 0.9076 - val_accuracy: 0.4623 - val_loss: 1.3448\n",
      "Epoch 70/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - accuracy: 0.6897 - loss: 0.9049 - val_accuracy: 0.4745 - val_loss: 1.3379\n",
      "Epoch 71/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 105ms/step - accuracy: 0.6917 - loss: 0.9058 - val_accuracy: 0.4745 - val_loss: 1.3199\n",
      "Epoch 72/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.6941 - loss: 0.8963 - val_accuracy: 0.4664 - val_loss: 1.3453\n",
      "Epoch 73/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 111ms/step - accuracy: 0.6826 - loss: 0.9179 - val_accuracy: 0.4786 - val_loss: 1.3392\n",
      "Epoch 74/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 123ms/step - accuracy: 0.7008 - loss: 0.8920 - val_accuracy: 0.4684 - val_loss: 1.3444\n",
      "Epoch 75/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 126ms/step - accuracy: 0.6966 - loss: 0.8903 - val_accuracy: 0.4664 - val_loss: 1.3537\n",
      "Epoch 76/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 110ms/step - accuracy: 0.6961 - loss: 0.8944 - val_accuracy: 0.4725 - val_loss: 1.3221\n",
      "Epoch 77/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 105ms/step - accuracy: 0.7089 - loss: 0.8786 - val_accuracy: 0.4786 - val_loss: 1.3150\n",
      "Epoch 78/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 106ms/step - accuracy: 0.7051 - loss: 0.8737 - val_accuracy: 0.4807 - val_loss: 1.3197\n",
      "Epoch 79/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 110ms/step - accuracy: 0.6952 - loss: 0.8898 - val_accuracy: 0.4684 - val_loss: 1.3478\n",
      "Epoch 80/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.6966 - loss: 0.8900 - val_accuracy: 0.4766 - val_loss: 1.3316\n",
      "Epoch 81/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 106ms/step - accuracy: 0.6977 - loss: 0.8801 - val_accuracy: 0.4766 - val_loss: 1.3411\n",
      "Epoch 82/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 103ms/step - accuracy: 0.7016 - loss: 0.8875 - val_accuracy: 0.4827 - val_loss: 1.3156\n",
      "Epoch 83/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 103ms/step - accuracy: 0.6865 - loss: 0.9099 - val_accuracy: 0.4766 - val_loss: 1.3354\n",
      "Epoch 84/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 109ms/step - accuracy: 0.6971 - loss: 0.8818 - val_accuracy: 0.4827 - val_loss: 1.3268\n",
      "Epoch 85/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 111ms/step - accuracy: 0.7004 - loss: 0.8822 - val_accuracy: 0.4929 - val_loss: 1.2882\n",
      "Epoch 86/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 104ms/step - accuracy: 0.7080 - loss: 0.8738 - val_accuracy: 0.4786 - val_loss: 1.3264\n",
      "Epoch 87/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 104ms/step - accuracy: 0.7048 - loss: 0.8725 - val_accuracy: 0.4766 - val_loss: 1.3266\n",
      "Epoch 88/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 91ms/step - accuracy: 0.7045 - loss: 0.8769 - val_accuracy: 0.4766 - val_loss: 1.3417\n",
      "Epoch 89/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 103ms/step - accuracy: 0.7045 - loss: 0.8887 - val_accuracy: 0.4847 - val_loss: 1.3223\n",
      "Epoch 90/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 103ms/step - accuracy: 0.7067 - loss: 0.8672 - val_accuracy: 0.4827 - val_loss: 1.3210\n",
      "Epoch 91/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.7111 - loss: 0.8725 - val_accuracy: 0.4786 - val_loss: 1.3225\n",
      "Epoch 92/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.7074 - loss: 0.8685 - val_accuracy: 0.4888 - val_loss: 1.3105\n",
      "Epoch 93/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 106ms/step - accuracy: 0.7081 - loss: 0.8674 - val_accuracy: 0.4868 - val_loss: 1.3182\n",
      "Epoch 94/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 105ms/step - accuracy: 0.7011 - loss: 0.8685 - val_accuracy: 0.4766 - val_loss: 1.3421\n",
      "Epoch 95/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 112ms/step - accuracy: 0.7155 - loss: 0.8428 - val_accuracy: 0.4847 - val_loss: 1.3218\n",
      "Epoch 96/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 104ms/step - accuracy: 0.7107 - loss: 0.8635 - val_accuracy: 0.4888 - val_loss: 1.3003\n",
      "Epoch 97/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.7046 - loss: 0.8759 - val_accuracy: 0.4786 - val_loss: 1.3236\n",
      "Epoch 98/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.7042 - loss: 0.8573 - val_accuracy: 0.4888 - val_loss: 1.3011\n",
      "Epoch 99/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.7090 - loss: 0.8514 - val_accuracy: 0.4827 - val_loss: 1.3052\n",
      "Epoch 100/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 105ms/step - accuracy: 0.7101 - loss: 0.8689 - val_accuracy: 0.4847 - val_loss: 1.3356\n",
      "Epoch 101/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 104ms/step - accuracy: 0.7073 - loss: 0.8618 - val_accuracy: 0.4908 - val_loss: 1.3291\n",
      "Epoch 102/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 135ms/step - accuracy: 0.6995 - loss: 0.8683 - val_accuracy: 0.4807 - val_loss: 1.3137\n",
      "Epoch 103/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 181ms/step - accuracy: 0.7060 - loss: 0.8734 - val_accuracy: 0.4807 - val_loss: 1.3219\n",
      "Epoch 104/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 177ms/step - accuracy: 0.7134 - loss: 0.8483 - val_accuracy: 0.4786 - val_loss: 1.3160\n",
      "Epoch 105/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 174ms/step - accuracy: 0.7142 - loss: 0.8591 - val_accuracy: 0.4847 - val_loss: 1.3103\n",
      "Epoch 106/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 173ms/step - accuracy: 0.7131 - loss: 0.8545 - val_accuracy: 0.4847 - val_loss: 1.2971\n",
      "Epoch 107/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 148ms/step - accuracy: 0.7084 - loss: 0.8581 - val_accuracy: 0.4847 - val_loss: 1.3018\n",
      "Epoch 108/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 98ms/step - accuracy: 0.6964 - loss: 0.8704 - val_accuracy: 0.4807 - val_loss: 1.3175\n",
      "Epoch 109/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 100ms/step - accuracy: 0.7078 - loss: 0.8584 - val_accuracy: 0.4888 - val_loss: 1.3044\n",
      "Epoch 110/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - accuracy: 0.7116 - loss: 0.8454 - val_accuracy: 0.4725 - val_loss: 1.3240\n",
      "Epoch 111/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - accuracy: 0.7156 - loss: 0.8501 - val_accuracy: 0.4827 - val_loss: 1.3163\n",
      "Epoch 112/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 95ms/step - accuracy: 0.7178 - loss: 0.8501 - val_accuracy: 0.4786 - val_loss: 1.3214\n",
      "Epoch 113/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 103ms/step - accuracy: 0.7099 - loss: 0.8670 - val_accuracy: 0.4827 - val_loss: 1.3109\n",
      "Epoch 114/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 109ms/step - accuracy: 0.7176 - loss: 0.8406 - val_accuracy: 0.4868 - val_loss: 1.3121\n",
      "Epoch 115/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 108ms/step - accuracy: 0.7080 - loss: 0.8517 - val_accuracy: 0.4847 - val_loss: 1.3038\n",
      "Epoch 116/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 108ms/step - accuracy: 0.7264 - loss: 0.8290 - val_accuracy: 0.4786 - val_loss: 1.3229\n",
      "Epoch 117/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 107ms/step - accuracy: 0.7095 - loss: 0.8712 - val_accuracy: 0.4807 - val_loss: 1.3175\n",
      "Epoch 118/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 107ms/step - accuracy: 0.7114 - loss: 0.8378 - val_accuracy: 0.4807 - val_loss: 1.3212\n",
      "Epoch 119/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 111ms/step - accuracy: 0.7111 - loss: 0.8663 - val_accuracy: 0.4766 - val_loss: 1.3298\n",
      "Epoch 120/120\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 131ms/step - accuracy: 0.7130 - loss: 0.8580 - val_accuracy: 0.4847 - val_loss: 1.3146\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_aug, y_aug,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=120,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "y_val_pred_probs = model.predict(X_val)\n",
    "y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "# 2) Compute confusion matrices\n",
    "cm_val = confusion_matrix(y_val, y_val_pred)\n",
    "cm_val_norm = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "class_names = list(le.classes_)\n",
    "num_classes = len(class_names)\n",
    "tick_marks = np.arange(num_classes)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))  # Adjust size as needed\n",
    "\n",
    "# Confusion Matrix - Validation (Counts)\n",
    "ax.imshow(cm_val, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.set_title(\"Validation Confusion Matrix (Counts)\")\n",
    "ax.set_xticks(tick_marks)\n",
    "ax.set_yticks(tick_marks)\n",
    "ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "ax.set_yticklabels(class_names)\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "\n",
    "for i in range(num_classes):\n",
    "    for j in range(num_classes):\n",
    "        ax.text(j, i, format(cm_val[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_val[i, j] > cm_val.max()/2 else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# F1 Score (macro, weighted, etc.)\n",
    "f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "print(f\"Macro F1-score: {f1:.4f}\")\n",
    "\n",
    "# Detailed report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract losses\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract losses\n",
    "train_loss = history.history['accuracy']\n",
    "val_loss = history.history['val_accuracy']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
